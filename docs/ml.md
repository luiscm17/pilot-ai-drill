# üó∫Ô∏è Mapa Completo de Machine Learning: Algoritmos, Preprocesamiento y Evaluaci√≥n

| Paradigma | Tipo de Problema | T√©cnicas Clave de Preprocesamiento | Algoritmos Principales | M√©tricas de Evaluaci√≥n |
| :--- | :--- | :--- | :--- | :--- |
| **Aprendizaje Supervisado** | **Regresi√≥n** (predecir valor continuo) | ‚Ä¢ Escalado de caracter√≠sticas<br>‚Ä¢ Manejo de valores nulos<br>‚Ä¢ Detecci√≥n de outliers<br>‚Ä¢ Ingenier√≠a de caracter√≠sticas | ‚Ä¢ **Lineales:** Regresi√≥n Lineal, Ridge, Lasso<br>‚Ä¢ **Ensambles:** Random Forest, XGBoost, Gradient Boosting<br>‚Ä¢ **Redes Neuronales:** MLP, CNN para series temporales<br>‚Ä¢ **Otros:** SVR, Decision Trees | ‚Ä¢ **MAE** (Error Absoluto Medio)<br>‚Ä¢ **MSE/RMSE** (Error Cuadr√°tico Medio/Ra√≠z)<br>‚Ä¢ **MAPE** (Error Porcentual Absoluto Medio)<br>‚Ä¢ **R¬≤** (Coeficiente de Determinaci√≥n) |
| | **Clasificaci√≥n** (predecir categor√≠a) | ‚Ä¢ Codificaci√≥n de variables categ√≥ricas<br>‚Ä¢ Balanceo de clases (SMOTE, undersampling)<br>‚Ä¢ Selecci√≥n de caracter√≠sticas<br>‚Ä¢ Escalado para SVM/NN | ‚Ä¢ **Lineales:** Regresi√≥n Log√≠stica, LDA<br>‚Ä¢ **Ensambles:** Random Forest, XGBoost, AdaBoost<br>‚Ä¢ **Vecinos:** k-NN<br>‚Ä¢ **Redes Neuronales:** MLP, CNN, Transformers<br>‚Ä¢ **Otros:** SVM, Na√Øve Bayes, Decision Trees | ‚Ä¢ **Matriz de Confusi√≥n**<br>‚Ä¢ **Precision, Recall, F1-Score**<br>‚Ä¢ **Exactitud (Accuracy)**<br>‚Ä¢ **Curva ROC & AUC**<br>‚Ä¢ **Log Loss** |
| | **Series Temporales** (predicci√≥n temporal) | ‚Ä¢ Creaci√≥n de lags y ventanas<br>‚Ä¢ Diferenciaci√≥n para estacionariedad<br>‚Ä¢ Manejo de estacionalidad<br>‚Ä¢ Engineering de caracter√≠sticas temporales | ‚Ä¢ **Cl√°sicos:** ARIMA, SARIMA, ETS, Prophet<br>‚Ä¢ **ML:** Random Forest, XGBoost con lags<br>‚Ä¢ **DL:** LSTM, GRU, Transformers temporales | ‚Ä¢ **MSE, MAE, MAPE**<br>‚Ä¢ **MASE** (Error Absoluto Escalado Medio)<br>‚Ä¢ **SMAPE** (Error Porcentual Absoluto Medio Sim√©trico) |
| **Aprendizaje No Supervisado** | **Clustering** (agrupamiento) | ‚Ä¢ Escalado de caracter√≠sticas (cr√≠tico)<br>‚Ä¢ Reducci√≥n de dimensionalidad<br>‚Ä¢ Normalizaci√≥n robusta a outliers | ‚Ä¢ **Centroides:** K-Means, K-Medoids<br>‚Ä¢ **Densidad:** DBSCAN, HDBSCAN<br>‚Ä¢ **Jer√°rquico:** Agglomerative Clustering<br>‚Ä¢ **Probabil√≠stico:** Gaussian Mixture Models | ‚Ä¢ **Silhouette Score**<br>‚Ä¢ **√çndice Davies-Bouldin**<br>‚Ä¢ **Calinski-Harabasz Index**<br>‚Ä¢ **ARI** (con labels verdaderas)<br>‚Ä¢ **Coeficiente de Silueta** |
| | **Reducci√≥n de Dimensionalidad** | ‚Ä¢ Escalado obligatorio<br>‚Ä¢ Normalizaci√≥n de datos<br>‚Ä¢ Manejo de valores nulos | ‚Ä¢ **Lineal:** PCA, SVD, LDA<br>‚Ä¢ **No Lineal:** t-SNE, UMAP, Autoencoders<br>‚Ä¢ **Manifold:** Isomap, LLE | ‚Ä¢ **Varianza Explicada Acumulada**<br>‚Ä¢ **Error de Reconstrucci√≥n**<br>‚Ä¢ **Preservaci√≥n de Estructura** |
| | **Detecci√≥n de Anomal√≠as** | ‚Ä¢ Escalado robusto<br>‚Ä¢ Normalizaci√≥n<br>‚Ä¢ Selecci√≥n de caracter√≠sticas relevantes | ‚Ä¢ **Basados en Ensamble:** Isolation Forest<br>‚Ä¢ **Densidad:** LOF (Local Outlier Factor)<br>‚Ä¢ **SVM:** One-Class SVM<br>‚Ä¢ **Redes:** Autoencoders, VAEs | ‚Ä¢ **F1-Score para clase minoritaria**<br>‚Ä¢ **Precision-Recall Curve**<br>‚Ä¢ **AUPRC** (√Årea bajo curva Precision-Recall)<br>‚Ä¢ **Tasa de Detecci√≥n con FPR fija** |
| **Aprendizaje por Refuerzo** | **Control/Decisiones Secuenciales** | ‚Ä¢ Normalizaci√≥n de estados/recompensas<br>‚Ä¢ Frame stacking<br>‚Ä¢ Discretizaci√≥n de espacios continuos | ‚Ä¢ **Value-based:** Q-Learning, DQN<br>‚Ä¢ **Policy-based:** REINFORCE, PPO<br>‚Ä¢ **Actor-Critic:** DDPG, SAC, A3C<br>‚Ä¢ **Model-based:** MuZero | ‚Ä¢ **Recompensa Acumulada Promedio**<br>‚Ä¢ **Tasa de √©xito/episodios**<br>‚Ä¢ **Convergencia del training**<br>‚Ä¢ **Eficiencia de muestreo** |

---
