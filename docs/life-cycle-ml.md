# üöÄ Gu√≠a Pr√°ctica: Ciclo de Vida de un Proyecto de Machine Learning

```yml
mi_proyecto_ml/
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Datos
‚îÇ   ‚îú‚îÄ‚îÄ raw/                        # Datos crudos (inmutables)
‚îÇ   ‚îú‚îÄ‚îÄ processed/                  # Datos procesados
‚îÇ   ‚îî‚îÄ‚îÄ external/                   # Datos de fuentes externas
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                      # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb               # An√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_model_experimentation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ src/                            # C√≥digo fuente (Python modules)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Scripts para procesar datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ make_dataset.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îú‚îÄ‚îÄ features/                   # Ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ build_features.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_selection.py
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # Entrenamiento y predicci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_dispatcher.py     # Mapeo de modelos
‚îÇ   ‚îî‚îÄ‚îÄ visualization/              # Visualizaciones
‚îÇ       ‚îî‚îÄ‚îÄ visualize.py
‚îÇ
‚îú‚îÄ‚îÄ models/                         # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ experiment_001/
‚îÇ   ‚îî‚îÄ‚îÄ experiment_002/
‚îÇ
‚îú‚îÄ‚îÄ metrics/                        # Resultados y m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ experiment_001/
‚îÇ   ‚îî‚îÄ‚îÄ experiment_002/
‚îÇ
‚îú‚îÄ‚îÄ config/                         # Archivos de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ params.yaml
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py
‚îÇ   ‚îî‚îÄ‚îÄ test_models.py
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias
‚îú‚îÄ‚îÄ environment.yml               # Environment de conda
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n
‚îî‚îÄ‚îÄ .gitignore                    # Archivos a ignorar en Git
```

## üìã **FASE 0: PREPARACI√ìN Y DEFINICI√ìN**

### **üéØ Definici√≥n del Problema**

```python
# Antes de codificar, responde:
business_problem = "¬øQu√© problema de negocio resolvemos?"
success_metrics = "¬øC√≥mo medimos el √©xito? (AUC > 0.85, MAE < 1000, etc.)"
available_data = "¬øQu√© datos tenemos disponibles?"
constraints = "¬øLimitaciones de tiempo/recursos?"
```

### **üõ†Ô∏è Setup del Entorno**

```bash
# Estructura m√≠nima viable
mkdir -p {data/{raw,processed},notebooks,src/{data,models,features},models,metrics,config}
touch requirements.txt README.md .gitignore
```

**requirements.txt inicial:**

```txt
pandas>=1.5.0
scikit-learn>=1.0.0
jupyter>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0
```

---

## üîç **FASE 1: AN√ÅLISIS EXPLORATORIO (EDA)**

### **üìä Objetivos del EDA**

```python
# notebooks/01_eda.ipynb
"""
‚úÖ Entender la distribuci√≥n de variables
‚úÖ Identificar valores nulos y outliers
‚úÖ Analizar correlaciones
‚úÖ Formular hip√≥tesis iniciales
"""
```

### **üîß T√©cnicas Esenciales**

```python
# C√≥digo t√≠pico de EDA
def basic_eda(df):
    print("Forma del dataset:", df.shape)
    print("\nValores nulos:")
    print(df.isnull().sum())
    print("\nEstad√≠sticas descriptivas:")
    print(df.describe())
    
    # Visualizaciones clave
    df.hist(figsize=(12, 10))
    plt.show()
    
    # Matriz de correlaci√≥n
    plt.figure(figsize=(10, 8))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
    plt.show()
```

---

## üßπ **FASE 2: PREPROCESAMIENTO**

### **üéØ Crear Pipeline de Datos**

```python
# src/data/make_dataset.py
def create_processing_pipeline():
    numerical_features = ['age', 'income', 'score']
    categorical_features = ['category', 'city']
    
    numerical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numerical_transformer, numerical_features),
            ('cat', categorical_transformer, categorical_features)
        ])
    
    return preprocessor
```

### **üìù Checklist de Preprocesamiento**

- [ ] Manejo de valores nulos
- [ ] Codificaci√≥n de variables categ√≥ricas
- [ ] Escalado/normalizaci√≥n
- [ ] Manejo de outliers
- [ ] Feature engineering b√°sico
- [ ] Divisi√≥n train/validation/test

---

## ü§ñ **FASE 3: MODELADO Y EXPERIMENTACI√ìN**

### **üìà Estrategia de Experimentaci√≥n**

```python
# src/models/train.py
def run_baseline_models(X_train, y_train, X_val, y_val):
    models = {
        'logistic_regression': LogisticRegression(random_state=42),
        'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'xgboost': XGBClassifier(random_state=42),
        'svm': SVC(probability=True, random_state=42)
    }
    
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict_proba(X_val)[:, 1]
        auc_score = roc_auc_score(y_val, y_pred)
        results[name] = auc_score
    
    return results
```

### **üéõÔ∏è Configuraci√≥n de Hiperpar√°metros**

```yaml
# config/params.yaml
random_forest:
  n_estimators: [50, 100, 200]
  max_depth: [5, 10, 15]
  min_samples_split: [2, 5, 10]

xgboost:
  learning_rate: [0.01, 0.1, 0.3]
  n_estimators: [100, 200, 300]
  max_depth: [3, 6, 9]
```

---

## üìä **FASE 4: EVALUACI√ìN Y SELECCI√ìN**

### **üìã M√©tricas por Tipo de Problema**

```python
def evaluate_model(model, X_test, y_test, problem_type='classification'):
    if problem_type == 'classification':
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
        
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1': f1_score(y_test, y_pred),
            'roc_auc': roc_auc_score(y_test, y_proba) if y_proba is not None else None
        }
    
    elif problem_type == 'regression':
        y_pred = model.predict(X_test)
        metrics = {
            'mae': mean_absolute_error(y_test, y_pred),
            'mse': mean_squared_error(y_test, y_pred),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
            'r2': r2_score(y_test, y_pred)
        }
    
    return metrics
```

---

## üöÄ **FASE 5: DESPLIEGUE Y DOCUMENTACI√ìN**

### **üì¶ Empaquetado del Modelo Final**

```python
# src/models/predict.py
def save_final_pipeline(model, preprocessor, feature_names):
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    
    # Guardar pipeline completo
    joblib.dump(pipeline, 'models/final_pipeline.joblib')
    
    # Guardar metadata
    metadata = {
        'feature_names': feature_names,
        'model_version': '1.0',
        'training_date': datetime.now().isoformat(),
        'metrics': final_metrics
    }
    
    with open('models/metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)
```

### **üìñ Documentaci√≥n Esencial**

```markdown
# README.md

## Resumen del Proyecto
- **Problema**: Clasificaci√≥n de riesgo crediticio
- **Mejor modelo**: XGBoost (AUC: 0.89)
- **Features principales**: income, credit_history, debt_ratio

## C√≥mo reproducir
1. Instalar dependencias: `pip install -r requirements.txt`
2. Ejecutar pipeline: `python src/models/train.py`
3. Resultados en: `metrics/final/`

## Estructura
```

proyecto/
‚îú‚îÄ‚îÄ data/           # Datos crudos y procesados
‚îú‚îÄ‚îÄ notebooks/      # An√°lisis exploratorio
‚îú‚îÄ‚îÄ src/           # C√≥digo fuente
‚îú‚îÄ‚îÄ models/        # Modelos entrenados
‚îî‚îÄ‚îÄ metrics/       # Resultados y evaluaciones

```
```

---

## ‚ö° **PLANTILLA DE GITIGNORE**

```gitignore
# Datos
data/raw/
data/processed/

# Modelos
models/
*.joblib
*.pkl

# Notebooks
notebooks/.ipynb_checkpoints/

# Entornos virtuales
venv/
.env

# Archivos temporales
*.tmp
*.log
```

---

## üéØ **CHECKLIST DE ENTREGA**

### **‚úÖ Antes de Empezar**

- [ ] Objetivo de negocio claro definido
- [ ] M√©tricas de √©xito establecidas
- [ ] Estructura de proyecto creada
- [ ] Entorno de desarrollo configurado

### **‚úÖ Durante Desarrollo**

- [ ] EDA completo documentado
- [ ] Pipeline de preprocesamiento robusto
- [ ] M√∫ltiples algoritmos probados
- [ ] Hiperpar√°metros optimizados
- [ ] Validaci√≥n cruzada implementada

### **‚úÖ Al Finalizar**

- [ ] Modelo final seleccionado y guardado
- [ ] M√©tricas de evaluaci√≥n reportadas
- [ ] C√≥digo documentado y organizado
- [ ] README con instrucciones claras
- [ ] Repositorio versionado y limpio

---

## üìä **GESTI√ìN DEL TIEMPO RECOMENDADA**

| Fase | Tiempo Estimado | Actividades Clave |
|------|-----------------|-------------------|
| **Preparaci√≥n** | 10% | Definici√≥n, setup, EDA |
| **Preprocesamiento** | 30% | Limpieza, feature engineering |
| **Modelado** | 40% | Experimentaci√≥n, tuning |
| **Evaluaci√≥n** | 15% | Validaci√≥n, selecci√≥n |
| **Documentaci√≥n** | 5% | Empaquetado, reportes |
